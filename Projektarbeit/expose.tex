\documentclass[a4paper,12pt]{article}
\usepackage{graphicx}
\usepackage{hyperref}

\title{Erkennung von KI-generierten Bildern mittels CNN}
\author{Duncan Scholle}
\date{\today}

\begin{document}

\maketitle

\section{Thema und Problemstellung}

Mit dem Fortschritt von generativer Künstlicher Intelligenz (KI) sind Bilder, die von Modellen wie DALL·E, MidJourney oder Stable Diffusion erzeugt werden, immer realistischer geworden. Diese Entwicklung bringt sowohl kreative als auch ethische Herausforderungen mit sich, insbesondere in Bezug auf Fälschungen und Deepfake-Technologien. Die automatische Erkennung solcher Bilder ist entscheidend für Bereiche wie Journalismus, digitale Forensik und soziale Netzwerke.

Convolutional Neural Networks (CNNs) sind ein leistungsfähiges Werkzeug zur Bildanalyse und Mustererkennung. In dieser Arbeit soll untersucht werden, inwiefern CNNs in der Lage sind, KI-generierte Bilder von echten Fotografien oder anderen digitalen Medien zu unterscheiden.

\section{Zielsetzung der Arbeit}

Das Ziel der Arbeit ist es, ein auf CNN basierendes Modell zu entwickeln, das KI-generierte Bilder mit hoher Genauigkeit von echten Bildern unterscheiden kann. Dabei sollen folgende Fragestellungen untersucht werden:

\begin{itemize}
    \item Welche Merkmale in Bildern lassen sich für die Unterscheidung zwischen echten und KI-generierten Bildern nutzen?
    \item Welche Architektur eines CNN eignet sich am besten für diese Klassifikation?
    \item Wie hoch ist die Erkennungsgenauigkeit eines trainierten CNN-Modells in Abhängigkeit von der Trainingsdatenmenge und -qualität?
    \item Welche Herausforderungen bestehen bei der Erkennung von KI-generierten Bildern?
\end{itemize}

\section{Methodik und Vorgehensweise}

\subsection{Theoretische Grundlagen}

\begin{itemize}
    \item Einführung in generative KI und Bildgeneratoren
    \item Funktionsweise von Convolutional Neural Networks (CNN)
    \item Überblick über existierende Ansätze zur Erkennung von KI-generierten Bildern
\end{itemize}

\subsection{Datensammlung und -aufbereitung}

\begin{itemize}
    \item Beschaffung eines geeigneten Datensatzes bestehend aus:
    \begin{itemize}
        \item Echten Bildern (z. B. von Open-Source-Datenbanken wie ImageNet oder COCO)
        \item KI-generierten Bildern (z. B. aus MidJourney, DALL·E, Stable Diffusion)
    \end{itemize}
    \item Preprocessing der Daten (Normalisierung, Resizing, Augmentierung)
\end{itemize}

\subsection{Entwicklung des CNN-Modells}

\begin{itemize}
    \item Auswahl einer geeigneten Architektur (z. B. VGG16, ResNet, EfficientNet)
    \item Anpassung der Architektur für die binäre Klassifikation (echt vs. KI-generiert)
    \item Implementierung des Modells in Python mit TensorFlow/Keras oder PyTorch
    \item Training des CNN mit verschiedenen Datensätzen und Optimierung der Hyperparameter
\end{itemize}

\subsection{Evaluierung und Tests}

\begin{itemize}
    \item Validierung des Modells mit Testdaten
    \item Berechnung von Metriken wie Accuracy, Precision, Recall und F1-Score
    \item Analyse von Fehlklassifikationen und potenziellen Verbesserungen
\end{itemize}

\subsection{Vergleich mit anderen Methoden}

\begin{itemize}
    \item Gegenüberstellung mit klassischen Bildanalyseverfahren
    \item Betrachtung von Alternativansätzen wie Transformer-basierte Modelle oder andere ML-Techniken
\end{itemize}

\subsection{Herausforderungen und Limitationen}

\begin{itemize}
    \item Bias in Trainingsdaten und deren Einfluss auf die Modellleistung
    \item Manipulationstechniken, die das Modell austricksen könnten (z. B. Rauschen, Wasserzeichen)
    \item Zukunftsperspektiven und mögliche Weiterentwicklungen
\end{itemize}

\section{Erwartete Ergebnisse}

\begin{itemize}
    \item Ein trainiertes CNN-Modell mit hoher Genauigkeit zur Erkennung von KI-generierten Bildern
    \item Erkenntnisse über typische Unterschiede zwischen echten und KI-generierten Bildern
    \item Bewertung der Effektivität des entwickelten Modells im Vergleich zu bestehenden Lösungen
\end{itemize}

\section{Zeitplan}

\begin{tabular}{|c|l|c|}
\hline
\textbf{Phase} & \textbf{Aufgabe} & \textbf{Zeitrahmen} \\
\hline
1 & Literaturrecherche und Theoretische Grundlagen & Woche 1-2 \\
2 & Datensammlung und -aufbereitung & Woche 3-4 \\
3 & Modellarchitektur wählen und implementieren & Woche 5-6 \\
4 & Training und Optimierung & Woche 7-8 \\
5 & Evaluierung und Tests & Woche 9-10 \\
6 & Dokumentation und Verfassen der Arbeit & Woche 11-12 \\
\hline
\end{tabular}

\section{Relevante Technologien und Tools}

\begin{itemize}
    \item Programmiersprachen: Python
    \item Frameworks \& Bibliotheken: TensorFlow/Keras, PyTorch, OpenCV, Scikit-Learn
    \item Datenquellen: ImageNet, COCO, generative KI-Modelle
    \item Hardware: GPU-Beschleunigung für schnelleres Training (z. B. NVIDIA CUDA)
\end{itemize}

\section{Fazit und Bedeutung der Arbeit}

Mit dieser Arbeit soll ein praxisnahes Modell entwickelt werden, das zur Bekämpfung von KI-gestützter Desinformation beitragen kann. Die Ergebnisse könnten für Forschungseinrichtungen, Journalismus und digitale Forensik von Bedeutung sein. Zudem sollen die Herausforderungen und Limitationen der Erkennung von KI-generierten Bildern beleuchtet werden.

\section{Literaturverzeichnis}

\begin{thebibliography}{9}

\bibitem{hemmert2018}
Hemmert-Pottmann, Thomas. 
\textit{Dämpferdefektdiagnose mittels der Deep Learning Architektur Convolutional Neural Networks}.
Technische Universität München, 2018.
\url{https://mediatum.ub.tum.de/doc/1464098/file.pdf}

\bibitem{cardenas2022}
Cardenas, Luisa. 
\textit{Erklärbarkeit von Merkmalserkennung keltischer Münzen bei Convolutional Neural Networks}.
Goethe-Universität Frankfurt, 2022.
\url{http://www.bigdata.uni-frankfurt.de/wp-content/uploads/2022/05/Bachelorarbeit_Luisa_Cardenas_Public_compressed.pdf}

\bibitem{goetz2021}
Götz, Thomas. 
\textit{Verbesserung der Vorhersagequalität von KI-Modellen mittels GANs}.
Deutsche Gesellschaft für Qualität, 2021.
\url{https://www.dgq.de/fachbeitraege/verbesserung-der-vorhersagequalitaet-von-ki-modellen-mittels-gans-generative-adversarial-neural-networks/}

\bibitem{springer2024}
Wang, Tianyi; Liao, Xin; Chow, Kam Pui; Lin, Xiaodong; Wang, Yinglong.
\textit{Deepfake Detection: A Comprehensive Survey from the Reliability Perspective}.
ACM Computing Surveys, 2024.
\url{https://arxiv.org/abs/2211.10881}

\bibitem{stuttgart2023}
Pelzer, Marius.
\textit{Quantitative Evaluation visueller Erklärungsverfahren für Convolutional Neural Networks}.
Universität Stuttgart, 2020.
\url{https://elib.uni-stuttgart.de/server/api/core/bitstreams/1862df7d-74aa-4e2a-aeef-27f4a0733070/content}

\bibitem{li2018deepfake}
Li, Yuezun; Lyu, Siwei.
\textit{Exposing DeepFake Videos By Detecting Face Warping Artifacts}.
Arxiv, 2018.
\url{https://arxiv.org/abs/1811.00656}

\bibitem{albadawy2019speech}
AlBadawy, Ehab A.; Lyu, Siwei; Farid, Hany.
\textit{Detecting AI-Synthesized Speech Using Bispectral Analysis}.
IEEE, 2019.
\url{https://farid.berkeley.edu/downloads/publications/cvpr19/cvpr19b.pdf}

\bibitem{qi2020deeprhythm}
Qi, Hua; Guo, Qing; Juefei-Xu, Felix; Xie, Xiaofei; Ma, Lei; Feng, Wei; Liu, Yang; Zhao, Jianjun.
\textit{DeepRhythm: Exposing DeepFakes with Attentional Visual Heartbeat Rhythms}.
ACM, 2020.
\url{https://arxiv.org/abs/2006.07634}

\end{thebibliography}



\end{document}
