%─────────────────────────────────────────────────────────────────────────────
% Kapitel 2: Datensätze
%─────────────────────────────────────────────────────────────────────────────
\chapter{Datensätze}
\label{chap:datensaetze}

In diesem Kapitel werden die für die Klassifikation von Deepfake- und Real-Bildern eingesetzten Datensätze vorgestellt sowie deren organisatorische Struktur und technische Vorverarbeitung erläutert. Ziel ist es, eine umfassende Übersicht über Quellen, Aufbereitung und Verteilung der Daten bereitzustellen.

\section{Verwendete Datensätze}

\begin{itemize}
    \item \textbf{Deepfake-vs-Real-Classification}\cite{prithivmlmods_2025}:  
    Deepfake-vs-Real-60K ist ein großskaliger Bildklassifikationsdatensatz zur Unterscheidung zwischen Deepfake- und realen Gesichtern. Er umfasst ca. 60.000 hochqualitative Bilder, bestehend aus etwa 30.000 Fake-Bildern (Label 0) und 30.000 Real-Bildern (Label 1), und unterstützt das Training, die Evaluation sowie das Benchmarking von Deepfake-Detektionsmodellen. Durch die nahezu ausgeglichene Klassenverteilung und die Vielfalt der Motive soll eine hohe Klassifikationsgenauigkeit und Generalisierbarkeit gewährleistet werden.
    
    \textbf{Key Features:}
    \begin{itemize}
        \item ca. 30.000 Deepfake-Bilder (Label 0)
        \item ca. 30.000 Real-Bilder (Label 1)
        \item Entwickelt für Bildklassifikationsaufgaben
        \item Unterstützung von Training, Evaluation und Benchmarking
        \item Ausgewogene Klassenverteilung und hochwertige Samples
    \end{itemize}
    
    Nach eigenen Beobachtungen stammen viele der als „Fake“ gelabelten Bilder aus öffentlich verfügbaren Social-Media-Quellen (z.\,B. Instagram-Posts mit Filtern) und zeigen teilweise Filtereffekte statt klassischer Deepfake-Manipulationen.

    \item \textbf{Detect AI-Generated Faces: High-Quality Dataset}\footnote{\url{https://www.kaggle.com/datasets/shahzaibshazoo/detect-ai-generated-faces-high-quality-dataset}}:  
    Ein kleiner, aber qualitativ besonders hochwertiger Datensatz, der speziell für die Unterscheidung von KI-generierten Gesichtern entwickelt wurde. Er enthält 1.001 Fake-Bilder und 2.002 Real-Bilder, jeweils mit klarer Zuordnung.

    \item \textbf{deepfake and real images}\footnote{\url{https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images}}:  
    Der größte im Projekt verwendete Datensatz umfasst rund 95.092 als \emph{fake} und 95.213 als \emph{real} gelabelte Bilder, insgesamt also etwa 190.000 Gesichter. Die Bilder sind im Standardformat (256×256 Pixel, JPG) verfügbar.
\end{itemize}

\section{Datenorganisation und -aufteilung}

Um eine einheitliche und automatisiert verarbeitbare Datenbasis für das Deep-Learning-Modell zu schaffen, wurden sämtliche Bilder in folgende Verzeichnisstruktur überführt:

\begin{verbatim}
Dataset/
├─ train/
│  ├─ real/
│  └─ fake/
├─ validation/
│  ├─ real/
│  └─ fake/
└─ test/
   ├─ real/
   └─ fake/
\end{verbatim}

Die Bilder wurden anhand ihrer Ursprungsdatensätze und Labels den jeweiligen Unterordnern \texttt{real} und \texttt{fake} zugeordnet und auf die drei Datensplits Training, Validierung und Test verteilt.

\section{Vorverarbeitung und Datenpipeline}

Die technische Vorverarbeitung der Bilder erfolgt im Training vollständig automatisiert durch den Einsatz eines \texttt{ImageDataGenerator} aus Keras, kombiniert mit der spezifischen Vorverarbeitungsfunktion für ResNet50 (\texttt{preprocess\_input}). Das Vorgehen ist wie folgt:

\begin{itemize}
    \item \textbf{Bildgröße:}  
    Beim Laden werden alle Bilder auf eine einheitliche Auflösung von 256×256 Pixeln angepasst (\texttt{target_size=(256,256)}), um optimal mit der Architektur von ResNet50 zu harmonieren.

    \item \textbf{Normalisierung:}  
    Die Pixelwerte werden kanalweise gemäß der ResNet50-Konvention skaliert und normalisiert, um einen stabilen Wertebereich für das Netzwerk zu gewährleisten.

    \item \textbf{Datenaugmentation:}  
    Der finale Stand verzichtet vollständig auf künstliche Erweiterungen oder Verzerrungen. Die Trainingsdaten werden somit ohne zusätzliche Transformationen verwendet.

    \item \textbf{Batch-Größe und Label-Encoding:}  
    Die Daten werden in Batches zu je 64 Bildern geladen. Die Klassenzuordnung (Real vs. Fake) erfolgt automatisch anhand der Verzeichnisstruktur und wird als binäres Label (0/1) dem Modell zugeführt.
\end{itemize}

\section{Zusammenfassung der Datenbasis}

Nach Abschluss der Vorverarbeitung standen folgende Datenmengen zur Verfügung:

\begin{itemize}
    \item \textbf{Deepfake-vs-Real-Classification}: ca. 30.000 Real, 30.000 Fake
    \item \textbf{Detect AI-Generated Faces}: 2.002 Real, 1.001 Fake
    \item \textbf{deepfake and real images}: ca. 95.213 Real, 95.092 Fake
\end{itemize}

Durch die einheitliche Struktur und konsequente Normalisierung wurden optimale Voraussetzungen geschaffen, um ein robustes Deep-Learning-Modell auf Basis großer und vielseitiger Bilddaten zu trainieren. Auf manuelle oder künstliche Balancierung der Klassen wurde bewusst verzichtet, da die Datensätze bereits eine weitgehende Gleichverteilung aufweisen.
