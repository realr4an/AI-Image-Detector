AI-Detector Trainingsskript â€“ Dokumentation
============================================

ğŸ§  ZIEL:
-------
Training eines CNN-Modells zur binÃ¤ren Klassifikation (z.B. "Echt" vs. "KI-generiert") mit Hilfe von Transfer Learning (ResNet50) unter Verwendung von TensorFlow / Keras.

ğŸ“ DATENSTRUKTUR:
-----------------
Dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Klasse1/
â”‚   â””â”€â”€ Klasse2/
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ Klasse1/
â”‚   â””â”€â”€ Klasse2/
â””â”€â”€ test/            (optional, nur fÃ¼r finale Evaluation)

ğŸ“Œ URSPRÃœNGLICHES TRAINING (erste Version):
-------------------------------------------
1. Verwendung von ResNet50 mit vortrainierten ImageNet-Gewichten.
2. Gefrorene ResNet50-Layer (keine Fine-Tuning-Phase).
3. Dense-Klassifikationskopf: Flatten â†’ Dense(128, relu) â†’ Dropout(0.5) â†’ Dense(1, sigmoid).
4. Optimierung mit Adam, Loss: Binary Crossentropy.
5. Verwendung von Mixed Precision Training (float16).
6. Data Augmentation im Training (Rotation, Flip, Zoom, etc.).
7. Callbacks:
   - EarlyStopping
   - ModelCheckpoint
   - ReduceLROnPlateau
8. Speicherung des besten Modells (`best_model.h5`) und finales Modell (`model.h5`).
9. Optional: Test-Set-Auswertung (Loss, Accuracy).

âœ… VERBESSERUNGEN IN DER NEUEN VERSION:
----------------------------------------
1. **Modellstruktur**:
   - `Flatten()` â†’ ersetzt durch `GlobalAveragePooling2D()` fÃ¼r bessere Generalisierung.
   - Dense(128) jetzt mit L2-Regularisierung (`l2(0.001)`).

2. **Fine-Tuning**:
   - Nach initialem Training: letzte 10 Schichten des ResNet50-Modells werden freigegeben und mit kleiner Lernrate (`1e-5`) weitertrainiert.

3. **Trainingsphasen**:
   - Initialtraining: 10 Epochen mit eingefrorenen ResNet-Layern.
   - Fine-Tuning: zusÃ¤tzliche 10 Epochen mit teilweiser Freigabe der Basis.

4. **Monitoring & Visualisierung**:
   - **TensorBoard**-Callback hinzugefÃ¼gt: Logs werden unter `logs/fit/<timestamp>` gespeichert.
   - Histogramme & Metriken werden automatisch protokolliert.

5. **Evaluation**:
   - Nach dem Training wird auf dem Test-Set (sofern vorhanden) nicht nur Accuracy, sondern auch:
     - **Klassifikationsreport** (Precision, Recall, F1)
     - **Konfusionsmatrix** ausgegeben.

6. **CodequalitÃ¤t**:
   - Bessere Trennung der Trainingsphasen.
   - Logging-Ausgaben reduziert (`tf.get_logger().setLevel('ERROR')`).
   - Saubere Modellspeicherung: `best_model_initial.h5`, `best_model_finetuned.h5`, `model_final.h5`.

ğŸ”§ BENÃ–TIGTE PAKETE:
---------------------
- tensorflow
- scikit-learn (fÃ¼r Klassifikationsreport & Konfusionsmatrix)
- matplotlib (optional fÃ¼r Visualisierung)
- tensorboard

ğŸ“¦ INSTALLATIONSHINWEIS:
-------------------------
Falls scikit-learn fehlt:
    pip install scikit-learn

TensorBoard starten:
    tensorboard --logdir logs/fit

ğŸŒŸ FAZIT:
---------
Die Ã¼berarbeitete Version bietet:
- bessere Generalisierung
- gezielteres Training durch Fine-Tuning
- transparente Ãœberwachung durch TensorBoard
- bessere Analyse durch zusÃ¤tzliche Auswertungen

ğŸ“… NEUER STAND: 20.04.2025
---------------------------
Basierend auf weiteren Experimenten und Erkenntnissen aus der TensorBoard-Analyse wurde das Trainingssetup weiter verbessert:

1. **ErhÃ¶hte Epochenzahl**:
   - Sowohl das Initialtraining als auch das Fine-Tuning laufen nun Ã¼ber **20 Epochen** (statt 10).
   - Grund: Das Modell zeigte in den TensorBoard-Kurven (accuracy/loss), dass es bei 10 Epochen **noch nicht ausgelernt** war.

2. **Erweiterte Fine-Tuning-Tiefe**:
   - Statt nur 10 Schichten des ResNet50-Modells wurden jetzt die **letzten 50 Layer** zur weiteren Anpassung freigegeben.
   - Dies ermÃ¶glicht es dem Modell, feinere Unterschiede zwischen echten und KI-generierten Bildern besser zu lernen.
   - Hintergrund: Die Fake-Bilder im Datensatz sind qualitativ hochwertig und teils kaum unterscheidbar von realen â€“ das Modell benÃ¶tigt mehr KapazitÃ¤t zur Feinjustierung.

3. **Datenlage & Balance**:
   - Das Training basiert auf ca. **193.538 Bildern** mit **ausgewogener Klassenverteilung** (Real vs. Fake).
   - Damit sind ausreichende Daten vorhanden, um ein robustes Modell zu trainieren â€“ Datenmangel oder Klassenschiefe sind **keine Schwachpunkte**.

4. **Ziel der Verbesserungen**:
   - Besseres Ausnutzen der Datenmenge durch lÃ¤ngeres Training.
   - StÃ¤rkere Modellanpassung durch tiefere Integration des vortrainierten ResNet50.
   - Weiterhin Fokus auf Vermeidung von Overfitting durch EarlyStopping, L2-Regularisierung und Data Augmentation.

ğŸ“Œ Ausblick:
------------
Weitere Optimierungen kÃ¶nnten sich auf folgende Bereiche beziehen:
- **Erweiterte Augmentation** (z.â€¯B. Color Jitter, Helligkeit, Noise)
- **Andere Basismodelle** (EfficientNet, InceptionV3 etc.)
- **Multi-Metrik-Training** (kombinierter Verlust aus z.â€¯B. F1 und BCE)
- **Ensemble-Strategien** oder Model Averaging fÃ¼r die finale Klassifikation

ğŸ“… NEUER STAND: 20.04.2025 â€“ Feintuning-Optimierung & Metrik-Fokus
-------------------------------------------------------------------
ZusÃ¤tzlich zur ErhÃ¶hung der Epochen und der Erweiterung der Fine-Tuning-Tiefe wurden weitere gezielte Anpassungen vorgenommen, um insbesondere **Recall** und **F1-Score** zu verbessern:

1. **Feinere Lernratenanpassung im Fine-Tuning**:
   - Die Lernrate wurde von `1e-5` auf **`1e-6`** reduziert.
   - Ziel: feinfÃ¼hligere Anpassung der trainierten ResNet-Schichten ohne Ãœberanpassung.

2. **StÃ¤rkere Regularisierung gegen Overfitting**:
   - `Dropout`-Rate wurde von **0.5 auf 0.6** erhÃ¶ht.
   - Die L2-Regularisierung im Dense-Layer wurde verstÃ¤rkt: `l2(0.001)` â†’ `l2(0.002)`.

3. **Dynamischere Lernratenanpassung mit ReduceLROnPlateau**:
   - `factor` wurde auf **0.2** reduziert, `patience` auf **2**.
   - ZusÃ¤tzlich wurde eine `min_lr` von **`1e-7`** definiert, um Ã¼bermÃ¤ÃŸige Reduktion zu vermeiden.

4. **Erweiterung der Metriken: AUC (Area Under Curve)**:
   - Neben Accuracy wird nun auch der **AUC-Wert** getrackt (`tf.keras.metrics.AUC()`).
   - Dieser zeigt, wie gut das Modell unabhÃ¤ngig vom Schwellenwert zwischen den Klassen unterscheidet â€“ gerade bei Ã¤hnlichen Klassen sehr wertvoll.

5. **Erweiterbarer Fine-Tuning-Bereich (optional)**:
   - StandardmÃ¤ÃŸig werden die letzten **50 Layer** freigegeben.
   - Optional kann diese Zahl auf **100 oder mehr** erweitert werden, je nach Overfitting-Tendenz und Trainingsdauer.

ğŸ“Œ Ziel dieser Ã„nderungen:
--------------------------
- **Fokussierter Recall-Zuwachs**, ohne Precision zu verlieren.
- **Robustere Generalisierung** auf schwierige Fake/Real-Unterschiede.
- **Bessere Kontrolle** Ã¼ber den Trainingseinfluss durch fein abgestimmte Lernraten- und Regularisierungsmechanismen.

â­ï¸ NÃ¤chste Schritte:
----------------------
- Vergleich der neuen Trainingskurven in TensorBoard (Accuracy, Loss, AUC).
- Test auf bisher ungenutzten DatensÃ¤tzen (Cross-Validation oder Challenge-Sets).
- Integration eines Threshold-Tunings zur gezielten Optimierung der F1-Score.

ğŸ“… NEUER STAND: 22.04.2025 â€“ Tieferes Fine-Tuning & AUC-Tracking
-----------------------------------------------------------------
Im aktuellen Durchlauf wurde das Modell mit einem nochmals erweiterten Setup trainiert:

1. **Fine-Tuning von 100 ResNet50-Schichten**:
   - Ziel war es, dem Modell mehr LernkapazitÃ¤t fÃ¼r feine Unterschiede zwischen Real und Fake zu geben.
   - Trotz guter Trainings- und Validierungswerte zeigte das Testset jedoch eine **Verschlechterung der Generalisierung**.

2. **AUC-Metrik eingefÃ¼hrt**:
   - Das Modell loggt nun zusÃ¤tzlich die **Area Under Curve (AUC)** zur besseren Bewertung der Klassentrennung.
   - Im Test lag der AUC bei **0.7244**, was moderat, aber noch ausbaufÃ¤hig ist.

3. **Stabilisierung der Lernrate**:
   - Der Trainingsverlauf war konstant mit Lernratenanpassung (`ReduceLROnPlateau`) und feiner Nachregelung (`min_lr=1e-7`).

ğŸ“‰ Fazit:
---------
- Obwohl das Fine-Tuning tiefer ging, **verschlechterten sich Recall und F1-Score** auf dem Testset.
- Das Modell war im Validierungsset stark, aber **leicht Ã¼berangepasst** und **weniger robust im echten Test**.

ğŸ” Foregehen fÃ¼r den nÃ¤chsten Trainingsversuch:
---------------------------------------------------

1. **Fine-Tuning reduzieren** (z.â€¯B. nur -30 Layer):
   - Zu viel Fine-Tuning kann das vortrainierte Wissen Ã¼berschreiben.
   - Ziel: bessere Balance zwischen Anpassung und Generalisierung.

2. **Threshold-Tuning aktivieren**:
   - StandardmÃ¤ÃŸig wird bei `0.5` klassifiziert.
   - Ein dynamischer Schwellenwert (z.â€¯B. 0.4 oder 0.45) kÃ¶nnte den **Recall verbessern**, ohne die Precision drastisch zu senken.

3. **Neues Basismodell ausprobieren (EfficientNetB0)**:
   - EfficientNetB0 ist kleiner, effizienter und oft robuster bei feinen visuellen Unterschieden.
   - LÃ¤sst sich 1:1 gegen ResNet50 austauschen im aktuellen Code.

ğŸ“… NEUER STAND: 24.04.2025 â€“ Tieferes Fine-Tuning & AUC-Tracking

- Fine-Tuning reduziert auf -10 wieer



ğŸ“Š MODELLERGEBNISSE (TESTSET)
=============================

ğŸ“… Ergebnisse vom 14.04.2025
----------------------------

| Modellname               | Accuracy | Precision | Recall | F1-Score | AUC  | Epochen (init/ft) | Fine-Tune-Layer |
|--------------------------|----------|-----------|--------|----------|------|-------------------|-----------------|
| best_model_initial.h5    | 0.7051   | 0.7710    | 0.6053 | 0.6782   | â€“    | 10 / â€“            | 0               |
| best_model_finetuned.h5  | 0.7026   | 0.7706    | 0.5990 | 0.6741   | â€“    | 10 / 10           | 10              |
| model_final.h5 (v1)      | 0.7026   | 0.7706    | 0.5990 | 0.6741   | â€“    | 10 / 10           | 10              |

ğŸ“… Ergebnisse vom 20.04.2025
----------------------------

| Modellname               | Accuracy | Precision | Recall | F1-Score | AUC  | Epochen (init/ft) | Fine-Tune-Layer |
|--------------------------|----------|-----------|--------|----------|------|-------------------|-----------------|
| best_model_initial.h5*   | 0.7030   | 0.7866    | 0.5785 | 0.6667   | â€“    | 20 / â€“            | 0               |
| best_model_finetuned.h5* | 0.6914   | 0.7762    | 0.5608 | 0.6511   | â€“    | 20 / 20           | 50              |
| model_final.h5 (v2)      | 0.6914   | 0.7762    | 0.5608 | 0.6511   | â€“    | 20 / 20           | 50              |

ğŸ“… Ergebnisse vom 22.04.2025
----------------------------

| Modellname               | Accuracy | Precision | Recall | F1-Score | AUC   | Epochen (init/ft) | Fine-Tune-Layer |
|--------------------------|----------|-----------|--------|----------|-------|-------------------|-----------------|
| best_model_initial.h5**  | 0.7048   | 0.7678    | 0.6094 | 0.6795   | â€“     | 20 / â€“            | 0               |
| best_model_finetuned.h5**| 0.6669   | 0.7640    | 0.5082 | 0.6104   | â€“     | 20 / 20           | 100             |
| model_final.h5 (v3)      | 0.6654   | 0.7658    | 0.5017 | 0.6063   | 0.7244| 20 / 20           | 100             |

ğŸ“… Ergebnisse vom 24.04.2025
----------------------------

| Modellname                | Accuracy | Precision | Recall | F1-Score | AUC  | Epochen (init/ft) | Fine-Tune-Layer |
|---------------------------|----------|-----------|--------|----------|------|-------------------|-----------------|
| best_model_initial.h5***  | 0.7025   | 0.7682    | 0.6022 | 0.6752   | â€“    | 20 / â€“            | 0               |
| best_model_finetuned.h5***| 0.7027   | 0.7614    | 0.6131 | 0.6793   | â€“    | 20 / 20           | 10              |
| model_final.h5 (v4)       | 0.7027   | 0.7614    | 0.6131 | 0.6793   | â€“    | 20 / 20           | 10              |



> *AUC wird kÃ¼nftig geloggt, sobald im Training integriert.  
> ft = Fine-Tuning