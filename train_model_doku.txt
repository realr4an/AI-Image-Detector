AI-Detector Trainingsskript – Dokumentation
============================================

🧠 ZIEL:
-------
Training eines CNN-Modells zur binären Klassifikation (z.B. "Echt" vs. "KI-generiert") mit Hilfe von Transfer Learning (ResNet50) unter Verwendung von TensorFlow / Keras.

📁 DATENSTRUKTUR:
-----------------
Dataset/
├── train/
│   ├── Klasse1/
│   └── Klasse2/
├── validation/
│   ├── Klasse1/
│   └── Klasse2/
└── test/            (optional, nur für finale Evaluation)

📌 URSPRÜNGLICHES TRAINING (erste Version):
-------------------------------------------
1. Verwendung von ResNet50 mit vortrainierten ImageNet-Gewichten.
2. Gefrorene ResNet50-Layer (keine Fine-Tuning-Phase).
3. Dense-Klassifikationskopf: Flatten → Dense(128, relu) → Dropout(0.5) → Dense(1, sigmoid).
4. Optimierung mit Adam, Loss: Binary Crossentropy.
5. Verwendung von Mixed Precision Training (float16).
6. Data Augmentation im Training (Rotation, Flip, Zoom, etc.).
7. Callbacks:
   - EarlyStopping
   - ModelCheckpoint
   - ReduceLROnPlateau
8. Speicherung des besten Modells (`best_model.h5`) und finales Modell (`model.h5`).
9. Optional: Test-Set-Auswertung (Loss, Accuracy).

✅ VERBESSERUNGEN IN DER NEUEN VERSION:
----------------------------------------
1. **Modellstruktur**:
   - `Flatten()` → ersetzt durch `GlobalAveragePooling2D()` für bessere Generalisierung.
   - Dense(128) jetzt mit L2-Regularisierung (`l2(0.001)`).

2. **Fine-Tuning**:
   - Nach initialem Training: letzte 10 Schichten des ResNet50-Modells werden freigegeben und mit kleiner Lernrate (`1e-5`) weitertrainiert.

3. **Trainingsphasen**:
   - Initialtraining: 10 Epochen mit eingefrorenen ResNet-Layern.
   - Fine-Tuning: zusätzliche 10 Epochen mit teilweiser Freigabe der Basis.

4. **Monitoring & Visualisierung**:
   - **TensorBoard**-Callback hinzugefügt: Logs werden unter `logs/fit/<timestamp>` gespeichert.
   - Histogramme & Metriken werden automatisch protokolliert.

5. **Evaluation**:
   - Nach dem Training wird auf dem Test-Set (sofern vorhanden) nicht nur Accuracy, sondern auch:
     - **Klassifikationsreport** (Precision, Recall, F1)
     - **Konfusionsmatrix** ausgegeben.

6. **Codequalität**:
   - Bessere Trennung der Trainingsphasen.
   - Logging-Ausgaben reduziert (`tf.get_logger().setLevel('ERROR')`).
   - Saubere Modellspeicherung: `best_model_initial.h5`, `best_model_finetuned.h5`, `model_final.h5`.

🔧 BENÖTIGTE PAKETE:
---------------------
- tensorflow
- scikit-learn (für Klassifikationsreport & Konfusionsmatrix)
- matplotlib (optional für Visualisierung)
- tensorboard

📦 INSTALLATIONSHINWEIS:
-------------------------
Falls scikit-learn fehlt:
    pip install scikit-learn

TensorBoard starten:
    tensorboard --logdir logs/fit

🌟 FAZIT:
---------
Die überarbeitete Version bietet:
- bessere Generalisierung
- gezielteres Training durch Fine-Tuning
- transparente Überwachung durch TensorBoard
- bessere Analyse durch zusätzliche Auswertungen

📅 NEUER STAND: 20.04.2025
---------------------------
Basierend auf weiteren Experimenten und Erkenntnissen aus der TensorBoard-Analyse wurde das Trainingssetup weiter verbessert:

1. **Erhöhte Epochenzahl**:
   - Sowohl das Initialtraining als auch das Fine-Tuning laufen nun über **20 Epochen** (statt 10).
   - Grund: Das Modell zeigte in den TensorBoard-Kurven (accuracy/loss), dass es bei 10 Epochen **noch nicht ausgelernt** war.

2. **Erweiterte Fine-Tuning-Tiefe**:
   - Statt nur 10 Schichten des ResNet50-Modells wurden jetzt die **letzten 50 Layer** zur weiteren Anpassung freigegeben.
   - Dies ermöglicht es dem Modell, feinere Unterschiede zwischen echten und KI-generierten Bildern besser zu lernen.
   - Hintergrund: Die Fake-Bilder im Datensatz sind qualitativ hochwertig und teils kaum unterscheidbar von realen – das Modell benötigt mehr Kapazität zur Feinjustierung.

3. **Datenlage & Balance**:
   - Das Training basiert auf ca. **193.538 Bildern** mit **ausgewogener Klassenverteilung** (Real vs. Fake).
   - Damit sind ausreichende Daten vorhanden, um ein robustes Modell zu trainieren – Datenmangel oder Klassenschiefe sind **keine Schwachpunkte**.

4. **Ziel der Verbesserungen**:
   - Besseres Ausnutzen der Datenmenge durch längeres Training.
   - Stärkere Modellanpassung durch tiefere Integration des vortrainierten ResNet50.
   - Weiterhin Fokus auf Vermeidung von Overfitting durch EarlyStopping, L2-Regularisierung und Data Augmentation.

📌 Ausblick:
------------
Weitere Optimierungen könnten sich auf folgende Bereiche beziehen:
- **Erweiterte Augmentation** (z. B. Color Jitter, Helligkeit, Noise)
- **Andere Basismodelle** (EfficientNet, InceptionV3 etc.)
- **Multi-Metrik-Training** (kombinierter Verlust aus z. B. F1 und BCE)
- **Ensemble-Strategien** oder Model Averaging für die finale Klassifikation