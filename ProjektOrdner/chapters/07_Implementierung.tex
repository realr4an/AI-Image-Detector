%─────────────────────────────────────────────────────────────────────────────
% Kapitel 4: Implementierung
%─────────────────────────────────────────────────────────────────────────────
\chapter{Implementierung}
\label{chap:implementierung}

\section{Datensätze und Use-Case}
Zu Beginn wurde eine ausführliche Recherche durchgeführt, um geeignete Datensätze für die Bild-basierte Deepfake-Erkennung zu identifizieren. Da der Use-Case auf Einzelbildern und nicht auf Videos basiert, fiel die Wahl auf den Kaggle-Datensatz „Deepfake and Real Images“\footnote{\url{https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images}}:
\begin{itemize}
  \item \textbf{Inhalt:} 190.000 JPG-Bilder in 256×256 Pixel.
  \item \textbf{Aufteilung:} Training (140.000), Validation (39.400), Test (10.905).
  \item \textbf{Gründe:} ausreichendes Volumen für Deep-Learning, standardisierte Auflösung, annähernde Klassenbalance.
\end{itemize}

\section{Projektstruktur}
\begin{verbatim}
Projekt/
|-- data/
|   |-- train/     % 140.000 Trainingsbilder
|   |-- val/       % 39.400 Validierungsbilder
|   \-- test/      % 10.905 Testbilder
|-- models/
|   |-- best_model_initial.h5     % nach Phase 1
|   |-- best_model_finetuned.h5   % nach Phase 2
|   \-- model_final.h5            % finales Modell
\-- src/
    |-- train_model.py    % Modell-Definition, Training & Fine-Tuning
    \-- evaluate.py       % Evaluation, Klassifikationsreport, Konfusionsmatrix
\end{verbatim}

\section{Modelldefinition}
Der Kern des Trainingsskripts ist eine ResNet50-basierte Architektur, die Transfer Learning mit ImageNet-Gewichten nutzt. Anfangs wurden alle Basis-Layer eingefroren, später Teil-Fine-Tuning durchgeführt.

\begin{lstlisting}[language=Python, caption=Definition in \texttt{train\_model.py}]
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras import mixed_precision

# Mixed Precision aktivieren
mixed_precision.set_global_policy('mixed_float16')

def create_model(freeze_base: bool = True, l2_factor: float = 0.001, dropout_rate: float = 0.5):
    base = ResNet50(weights='imagenet', include_top=False, input_shape=(256,256,3))
    base.trainable = not freeze_base
    
    x = GlobalAveragePooling2D()(base.output)
    x = Dense(128, activation='relu', kernel_regularizer=l2(l2_factor))(x)
    x = Dropout(dropout_rate)(x)
    out = Dense(1, activation='sigmoid', dtype='float32')(x)
    
    model = tf.keras.Model(inputs=base.input, outputs=out)
    return model
\end{lstlisting}

\subsection*{Erklärung wichtiger Komponenten}
\begin{itemize}
  \item \textbf{Mixed Precision:} Float16 für schnellere GPU-Auslastung.
  \item \textbf{GlobalAveragePooling2D statt Flatten:} Reduziert Überanpassung.
  \item \textbf{L2-Regularisierung (0.001):} Verhindert zu große Gewichte.
  \item \textbf{Dropout (0.5):} Weitere Regularisierung.
\end{itemize}

\section{Training und Fine-Tuning}
Das Training erfolgte in zwei Phasen, jeweils mit Callbacks zur Steuerung und Optimierung.

\subsection{Phase 1: Initialtraining (10 Epochen)}
\begin{lstlisting}[language=Python, caption=Initialtraining in \texttt{train\_model.py}]
model = create_model(freeze_base=True, l2_factor=0.001, dropout_rate=0.5)
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='binary_crossentropy',
    metrics=['accuracy', tf.keras.metrics.AUC()]
)

# Data Augmentation: Rotation, Flip, Zoom etc. wird in train_dataset integriert
callbacks_phase1 = [
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    tf.keras.callbacks.ModelCheckpoint('models/best_model_initial.h5', monitor='val_accuracy', save_best_only=True),
    tf.keras.callbacks.TensorBoard(log_dir='logs/fit/initial', update_freq='epoch')
]

model.fit(
    train_dataset,
    epochs=10,
    validation_data=val_dataset,
    callbacks=callbacks_phase1
)
# Speichern des finalen Modells
model.save('models/model_initial_final.h5')
\end{lstlisting}

\subsection*{Phase 2: Fine-Tuning (10 Epochen)}
\begin{lstlisting}[language=Python, caption=Fine-Tuning in \texttt{train\_model.py}]
# Freigabe der obersten 10 Basisschichten
for layer in model.layers[-10:]:
    layer.trainable = True

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
    loss='binary_crossentropy',
    metrics=['accuracy', tf.keras.metrics.AUC()]
)

callbacks_phase2 = [
    tf.keras.callbacks.ModelCheckpoint('models/best_model_finetuned.h5', monitor='val_accuracy', save_best_only=True),
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7),
    tf.keras.callbacks.TensorBoard(log_dir='logs/fit/finetune', update_freq='epoch')
]

model.fit(
    train_dataset,
    epochs=10,
    validation_data=val_dataset,
    callbacks=callbacks_phase2
)
# Speichern als finales Modell
model.save('models/model_final.h5')
\end{lstlisting}

\section{Ergebnisse und iterative Anpassungen}
Nach jeder Phase wurde auf dem Testset evaluiert (Klassifikationsreport aus \texttt{sklearn.metrics} und Konfusionsmatrix mit \texttt{matplotlib}).

\subsection*{Ergebnisse vom 14.04.2025}
\begin{table}[h]
\centering
\caption{Performance nach 10/10 Epochen}
\begin{tabular}{lcccccc}
\toprule
Modell                         & Acc.   & Prec.  & Rec.   & F1     & AUC & Epochen (init/ft) \\
\midrule
best\_model\_initial.h5        & 0.7051 & 0.7710 & 0.6053 & 0.6782 & –   & 10 / –            \\
best\_model\_finetuned.h5      & 0.7026 & 0.7706 & 0.5990 & 0.6741 & –   & 10 / 10           \\
model\_final.h5 (v1)           & 0.7026 & 0.7706 & 0.5990 & 0.6741 & –   & 10 / 10           \\
\bottomrule
\end{tabular}
\end{table}

\subsection*{Anpassungen zum 20.04.2025}
\begin{itemize}
  \item Epochen auf 20 erhöht
  \item Fine-Tuning auf 50 Layer
  \item LR initial: \(1\times10^{-6}\)
  \item L2-Regularisierung: 0.002
  \item Dropout: 0.6
  \item ReduceLROnPlateau: factor=0.2, patience=2, min\_lr=1e-7
\end{itemize}
\begin{table}[h]
\centering
\caption{Performance nach 20/20 Epochen, 50 Layer}
\begin{tabular}{lcccccc}
\toprule
Modell                         & Acc.   & Prec.  & Rec.   & F1     & AUC & Epochen (init/ft) \\
\midrule
best\_model\_initial.h5*       & 0.7030 & 0.7866 & 0.5785 & 0.6667 & –   & 20 / –            \\
best\_model\_finetuned.h5*     & 0.6914 & 0.7762 & 0.5608 & 0.6511 & –   & 20 / 20           \\
model\_final.h5 (v2)           & 0.6914 & 0.7762 & 0.5608 & 0.6511 & –   & 20 / 20           \\
\bottomrule
\end{tabular}
\end{table}

\subsection*{Weitere Versuche zum 22.04.2025}
\begin{itemize}
  \item Fine-Tuning auf 100 Layer
\end{itemize}
\begin{table}[h]
\centering
\caption{Performance nach 20/20 Epochen, 100 Layer}
\begin{tabular}{lcccccc}
\toprule
Modell                         & Acc.   & Prec.  & Rec.   & F1     & AUC    & Epochen (init/ft) \\
\midrule
best\_model\_initial.h5**      & 0.7048 & 0.7678 & 0.6094 & 0.6795 & –      & 20 / –            \\
best\_model\_finetuned.h5**    & 0.6669 & 0.7640 & 0.5082 & 0.6104 & –      & 20 / 20           \\
model\_final.h5 (v3)           & 0.6654 & 0.7658 & 0.5017 & 0.6063 & 0.7244 & 20 / 20           \\
\bottomrule
\end{tabular}
\end{table}

\subsection*{Neuer Ansatz zum 24.04.2025}
\begin{itemize}
  \item Rückkehr zu 10 Layer Fine-Tuning + Thresholding (0.5)
  \item EfficientNetB0 als Basis getestet
\end{itemize}
\begin{table}[h]
\centering
\caption{Performance EfficientNetB0 (20/20, 10 Layer)}
\begin{tabular}{lcccccc}
\toprule
Modell                         & Acc.   & Prec.  & Rec.   & F1     & AUC & Epochen (init/ft) \\
\midrule
best\_model\_initial.h5***     & 0.7025 & 0.7682 & 0.6022 & 0.6752 & –   & 20 / –            \\
best\_model\_finetuned.h5***   & 0.7027 & 0.7614 & 0.6131 & 0.6793 & –   & 20 / 20           \\
model\_final.h5 (v4)           & 0.7027 & 0.7614 & 0.6131 & 0.6793 & –   & 20 / 20           \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Radikale Umstrukturierung}
Um Overfitting weiter zu reduzieren, wurde:
\begin{itemize}
  \item \textbf{Data Augmentation entfernt}, um verrauschte Gradienten durch starke Transformationen zu vermeiden.
  \item \textbf{LR-Patience auf 10 erhöht}, um dem Modell Zeit für langsame Anpassungen zu geben.
  \item \textbf{Fine-Tuning komplett ausgelassen}, um nur den vorkonfigurierten Kopf zu trainieren.
  \item \textbf{Zusätzlicher Datensatz} von Shahzaibshazoo\footnote{\url{https://www.kaggle.com/datasets/shahzaibshazoo/detect-ai-generated-faces-high-quality-dataset}} integriert, um die Bildvarianz und Robustheit zu steigern.
\end{itemize}
Diese Maßnahmen führten zu stabileren Lernkurven, höherem Recall und geringerer Overfitting-Tendenz. Insgesamt wurden 1.000 Epochen durchgeführt (Trainingsdauer etwa 3,5 Tage).

\paragraph{Klassifikationsreport}
\begin{verbatim}
              precision    recall  f1-score   support
      Fake       0.67      0.79      0.73      5825
      Real       0.76      0.63      0.69      6147
    accuracy                           0.71     11972
\end{verbatim}

\paragraph{Konfusionsmatrix}
\[
\begin{pmatrix}
4606 & 1219\\
2246 & 3901
\end{pmatrix}
\]

\section{Letzte Optimierung}
Abschließend wurde das gesamte ResNet50-Modell freigegeben und 50 Epochen trainiert, was eine sehr hohe Trennschärfe ermöglichte.

\paragraph{Klassifikationsreport}
\begin{verbatim}
              precision    recall  f1-score   support
      Fake       0.83      0.97      0.89      5825
      Real       0.96      0.81      0.88      6147
    accuracy                           0.89     11972
\end{verbatim}

\paragraph{Konfusionsmatrix}
\[
\begin{pmatrix}
5643 &  182\\
1149 & 4998
\end{pmatrix}
\]

\section{Ausblick}
Die erzielten Ergebnisse sind sehr zufriedenstellend. Weitere sinnvolle Erweiterungen:
\begin{itemize}
  \item \textbf{MobileNetV2-Integration} für ressourcenarme Umgebungen.
  \item \textbf{Gesichts-Extraktionspipeline} zur Fokussierung auf relevante Bildbereiche.
  \item \textbf{Zusätzliche Datensatz-Erweiterungen}, z.\,B. Deepfake vs. Real 60k, um Robustheit weiter zu steigern.
\end{itemize}
