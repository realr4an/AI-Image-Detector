%─────────────────────────────────────────────────────────────────────────────
% Kapitel 2: Datensätze
%─────────────────────────────────────────────────────────────────────────────
\chapter{Datensätze}
\label{chap:datensaetze}

Ein zentraler Baustein dieser Arbeit war die sorgfältige Auswahl und systematische Vorverarbeitung verschiedener Deepfake-Bilddatensätze, um eine robuste und realitätsnahe Klassifikation zu ermöglichen. Für das Training und die Evaluierung des Modells wurden insgesamt drei öffentliche Datensätze von Kaggle herangezogen, welche im Folgenden näher beschrieben werden.

\section{Verwendete Datensätze}

\begin{itemize}
    \item \textbf{Deepfake-vs-Real-Classification}\footnote{\url{https://www.kaggle.com/datasets/prithivsakthiur/deepfake-vs-real-60k}}:  
    Dieser Datensatz enthält etwa 28.600 echte (\emph{real}) und 28.600 Deepfake-Bilder (\emph{fake}), sodass beide Klassen annähernd gleich stark vertreten sind. Die Bilder liegen im JPG-Format vor und zeigen unterschiedlichste Gesichter in diversen Umgebungen.

    \item \textbf{Detect AI-Generated Faces: High-Quality Dataset}\footnote{\url{https://www.kaggle.com/datasets/shahzaibshazoo/detect-ai-generated-faces-high-quality-dataset}}:  
    Ein kleiner, aber qualitativ besonders hochwertiger Datensatz, der speziell für die Unterscheidung von KI-generierten Gesichtern entwickelt wurde. Er enthält 1.001 Fake-Bilder und 2.002 Real-Bilder, jeweils mit klarer Zuordnung.

    \item \textbf{deepfake and real images}\footnote{\url{https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images}}:  
    Der größte im Projekt verwendete Datensatz umfasst rund 95.092 als \emph{fake} und 95.213 als \emph{real} gelabelte Bilder, insgesamt also etwa 190.000 Gesichter. Die Bilder sind bereits im Standardformat (256x256 Pixel, JPG) verfügbar.
\end{itemize}

Alle Datensätze wurden zunächst unabhängig voneinander gesichtet, geprüft und nach den beiden Zielklassen (\emph{real}, \emph{fake}) kategorisiert.

\section{Datenorganisation und -aufteilung}

Um eine einheitliche und automatisiert verarbeitbare Datenbasis für das Deep-Learning-Modell zu schaffen, wurden sämtliche Bilder zunächst in eine gemeinsame Verzeichnisstruktur überführt:

\begin{verbatim}
Dataset/
|-- train/
|   |-- real/
|   \-- fake/
|-- validation/
|   |-- real/
|   \-- fake/
\-- test/
    |-- real/
    \-- fake/
\end{verbatim}

Die Bilder wurden anhand ihrer Ursprungsdatensätze und Labels den jeweiligen Unterordnern \texttt{real} und \texttt{fake} zugeordnet und dabei auf die drei Datensplits Training, Validierung und Test verteilt.

\section{Vorverarbeitung und Datenpipeline}

Die technische Vorverarbeitung der Bilder erfolgt im Training vollständig automatisiert durch den Einsatz eines \texttt{ImageDataGenerator} aus Keras, kombiniert mit der spezifischen Vorverarbeitungsfunktion für ResNet50 (\texttt{preprocess\_input}). Das Vorgehen ist wie folgt:

\begin{itemize}
    \item \textbf{Bildgröße:}  
    Alle Bilder werden beim Laden auf eine einheitliche Auflösung von 256x256 Pixeln gebracht (per \texttt{target\_size=(256, 256)}), um optimal mit der Architektur von ResNet50 zu harmonieren.

    \item \textbf{Normalisierung:}  
    Die Pixelwerte werden nicht nur skaliert, sondern gemäß der ResNet50-Konvention kanalweise normalisiert, um einen stabilen Wertebereich für das Netzwerk zu gewährleisten.

    \item \textbf{Datenaugmentation:}  
    Während zu Projektbeginn kurzzeitig verschiedene Augmentationstechniken (z.B. Rotation, Flip, Zoom) getestet wurden, verzichtet der finale Stand vollständig auf künstliche Erweiterungen oder Verzerrungen. Die Trainingsdaten werden also ohne zusätzliche Transformationen verwendet.

    \item \textbf{Batching und Label-Encoding:}  
    Die Bilddaten werden im Trainingsprozess in Batches zu je 64 Bildern geladen. Die Zuordnung zu den Klassen (\emph{real} oder \emph{fake}) erfolgt automatisch anhand der Verzeichnisstruktur und wird als binäre Label (0/1) dem Modell zugeführt.
\end{itemize}

Die Verwendung der \texttt{flow\_from\_directory}-Funktion gewährleistet, dass alle Splits (Training, Validation, Test) effizient und speicherschonend verarbeitet werden können.

\section{Zusammenfassung der Datenbasis}

Zusammengefasst standen nach Abschluss der Vorverarbeitung und Sortierung folgende Datenmengen für das Projekt zur Verfügung:

\begin{itemize}
    \item \textbf{Deepfake-vs-Real-Classification:} ca. 28.600 Real, 28.600 Fake
    \item \textbf{Detect AI-Generated Faces:} 2.002 Real, 1.001 Fake
    \item \textbf{deepfake and real images:} ca. 95.213 Real, 95.092 Fake
\end{itemize}

Durch die einheitliche Struktur und konsequente Normalisierung wurden optimale Voraussetzungen geschaffen, um ein robustes Deep-Learning-Modell auf Basis großer und vielseitiger Bilddaten zu trainieren. Auf manuelle oder künstliche Balancierung der Klassen wurde bewusst verzichtet, da die verwendeten Datensätze bereits eine weitgehende Gleichverteilung von echten und gefälschten Bildern aufweisen.
